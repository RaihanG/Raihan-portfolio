<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Md Raihan Goni | Academic Portfolio</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Academic portfolio of Md Raihan Goni, PhD researcher in AI for biomedical optics and medical imaging.">
    <link rel="stylesheet" href="style.css">

    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@500;700&family=Inter:wght@300;400;500;600&display=swap"
        rel="stylesheet">
</head>

<body>
    <!-- Navigation -->
    <header class="site-header">
        <div class="container nav-container">
            <div class="logo">
                <img src="assets/rg-logo.png" alt="RG logo" class="logo-mark">
                <a href="#top">Md Raihan Goni</a>
            </div>

            <nav class="nav-links">
                <a href="#about">About</a>
                <a href="#research">Research</a>
                <a href="#publications">Publications</a>
                <a href="#experience">Experience</a>
                <a href="#education">Education</a>
                <a href="#awards">Awards</a>
                <a href="#contact">Contact</a>

                <!-- Theme toggle -->
                <button id="theme-toggle" class="theme-toggle" type="button" aria-label="Switch to dark mode">
                    <span id="theme-toggle-icon" aria-hidden="true">üåô</span>
                </button>
            </nav>

        </div>
    </header>

    <main id="top">
        <!-- Hero / About -->
        <section id="about" class="section hero">
            <div class="container hero-grid">
                <div class="hero-text">
                    <p class="eyebrow">PhD Researcher ¬∑ AI in Optics & Medical AI</p>
                    <h1 class="hero-title">Md Raihan Goni</h1>
                    <p class="hero-subtitle">
                        PhD candidate in Electronics and Electrical Engineering at the University of Nottingham,
                        focusing on AI for biomedical optics, medical imaging, and signal processing.
                    </p>

                    <div class="hero-meta">
                        <p><strong>Location:</strong> Nottingham, UK</p>
                        <p><strong>Affiliations:</strong> University of Nottingham ¬∑ Universiti Sains Malaysia ¬∑
                            North
                            South University</p>
                    </div>

                    <div class="hero-actions">
                        <a href="https://orcid.org/0000-0002-2482-419X" target="_blank" class="btn secondary">
                            ORCID
                        </a>

                        <a href="https://www.researchgate.net/profile/Md-Raihan-Goni/publications" target="_blank"
                            class="btn secondary">
                            ResearchGate
                        </a>

                        <a href="https://scholar.google.com/citations?user=3hI2wOgAAAAJ&hl=en" target="_blank"
                            class="btn secondary">
                            Google Scholar
                        </a>

                        <a href="https://www.linkedin.com/in/raihan-goni/" target="_blank" class="btn secondary">
                            LinkedIn
                        </a>
                    </div>
                    <div class="hero-highlights">
                        <div class="hero-highlight">
                            <span class="hero-highlight-label">Focus</span>
                            <span class="hero-highlight-value">AI for biomedical optics & imaging</span>
                        </div>
                        <div class="hero-highlight">
                            <span class="hero-highlight-label">Teaching</span>
                            <span class="hero-highlight-value">University-level teaching & supervision</span>
                        </div>
                        <div class="hero-highlight">
                            <span class="hero-highlight-label">Background</span>
                            <span class="hero-highlight-value">Academic experience across Bangladesh, Malaysia &
                                UK</span>
                        </div>
                    </div>

                </div>

                <div class="hero-profile">
                    <!-- Replace assets/profile.jpg with your own image path -->
                    <div class="profile-image-wrapper">
                        <img src="assets/profile1.jpeg" alt="Portrait of Md Raihan Goni"
                            onerror="this.style.display='none'">
                    </div>
                    <div class="profile-card">
                        <h2>Current Position</h2>
                        <p><strong>PhD (AI in Optics)</strong><br>
                            University of Nottingham<br>
                            2024 ‚Äì present
                        </p>
                        <h3>Research Interests</h3>
                        <ul>
                            <li>AI for biomedical optics & imaging</li>
                            <li>Medical image segmentation & analysis</li>
                            <li>Biomedical signal processing</li>
                            <li>Interpretable & physics-informed deep learning</li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>

        <!-- Research Overview -->
        <section id="research" class="section">
            <div class="container">
                <h2 class="section-title">Research Overview</h2>
                <p>
                    My research focuses on developing robust and interpretable AI methods for biomedical
                    applications,
                    particularly within optics and medical imaging. I am interested in combining deep learning
                    with
                    domain knowledge to improve diagnostic accuracy, reliability, and clinical relevance.
                </p>

                <div class="card-grid">
                    <article class="card">
                        <h3>AI in Biomedical Optics</h3>
                        <p>
                            Designing machine learning models to extract quantitative information from optical
                            imaging
                            systems,
                            with a focus on improving reconstruction quality and interpretability.
                        </p>
                    </article>

                    <article class="card">
                        <h3>Medical Image Segmentation</h3>
                        <p>
                            Deep learning architectures for vascular and organ segmentation, including
                            attention-based
                            and kernel-filtering methods for cerebrovascular and lung imaging.
                        </p>
                    </article>

                    <article class="card">
                        <h3>Interpretable Multi-Task Models</h3>
                        <p>
                            Multi-task conditional neural networks for discovering clinically meaningful
                            patterns in
                            complex imaging modalities, such as phonon microscopy.
                        </p>
                    </article>

                    <article class="card">
                        <h3>Human Activity & Behaviour Analysis</h3>
                        <p>
                            Computer vision and pose-based deep learning for tasks such as violence and crowd
                            behaviour
                            detection.
                        </p>
                    </article>
                </div>
            </div>
        </section>

        <!-- Publications -->
        <section id="publications" class="section section-alt">
            <div class="container">
                <h2 class="section-title">Publications</h2>

                <h3 class="subheading">Journal Articles</h3>
                <ol class="pub-list">
                    <li>
                        Y. Zheng, R. Fuentes-Dom√≠nguez, <strong>Md Raihan Goni</strong>, M. Clark, A. McIntyre,
                        G. S. D.
                        Gordon, F. P√©rez-Cota,
                        <a href="https://doi.org/10.1109/JBHI.2025.3556599" target="_blank">‚ÄúInterpretable
                            Multi-Task
                            Conditional Neural Networks Reveal Cancer Cell Adhesion
                            Characteristics From Phonon Microscopy Images,‚Äù</a>
                        <em>IEEE Journal of Biomedical and Health Informatics</em>, vol. 29, no. 9, 2025.
                        <span class="pub-meta">DOI: 10.1109/JBHI.2025.3556599</span>
                        <details>
                            <summary class="paper-summary">Show Summary</summary>
                            <div class="summary-content">
                                Proposes a multi-task conditional neural network to analyze phonon microscopy
                                images,
                                revealing cancer cell adhesion characteristics with high interpretability.
                            </div>
                        </details>
                    </li>
                    <li>
                        Ahad, Yesmin, Ananna, Sumon, Hashem, <strong>Md Raihan Goni</strong>, M. Nabeel,
                        <a href="https://doi.org/10.24507/icicel.17.09.1005" target="_blank">"Leveraging Pose
                            Data
                            Towards a More Generalized Violence Detection System,"</a>
                        <em>ICIC Express Letters</em>, vol. 17, no. 9, pp. 1005‚Äì1011, 2023.
                        <span class="pub-meta">DOI: 10.24507/icicel.17.09.1005</span>
                        <details>
                            <summary class="paper-summary">Show Summary</summary>
                            <div class="summary-content">
                                Investigates the use of pose estimation data to improve the generalization and
                                accuracy
                                of violence detection systems across different scenarios.
                            </div>
                        </details>
                    </li>
                    <li>
                        <strong>Md Raihan Goni</strong>, N. I. R. Ruhaiyem, M. Mustapha, A. Achuthan, C. M. N.
                        Che Mohd
                        Nassir,
                        <a href="https://doi.org/10.1109/ACCESS.2022.3214987" target="_blank">‚ÄúBrain Vessel
                            Segmentation
                            Using Deep Learning‚ÄîA Review,‚Äù</a>
                        <em>IEEE Access</em>, vol. 10, pp. 111322‚Äì111336, 2022.
                        <span class="pub-meta">DOI: 10.1109/ACCESS.2022.3214987</span>
                        <details>
                            <summary class="paper-summary">Show Summary</summary>
                            <div class="summary-content">
                                A comprehensive review of deep learning techniques for brain vessel
                                segmentation,
                                highlighting current challenges and future research directions.
                            </div>
                        </details>
                    </li>
                    <li>
                        S. S. A. Sumon, <strong>Md Raihan Goni</strong>, N. B. Hashem, T. Shahria, R. Rahman,
                        <a href="https://doi.org/10.1142/S2196888820500013" target="_blank">‚ÄúViolence Detection
                            by
                            Pretrained Modules with Different Deep Learning Approaches,‚Äù</a>
                        <em>Vietnam Journal of Computer Science</em>, 7(1), 19‚Äì40, 2020.
                        <span class="pub-meta">DOI: 10.1142/S2196888820500013</span>
                        <details>
                            <summary class="paper-summary">Show Summary</summary>
                            <div class="summary-content">
                                Investigates the use of pretrained modules for violence detection.
                            </div>
                        </details>
                    </li>
                </ol>

                <h3 class="subheading">Conference Papers</h3>
                <ol class="pub-list">
                    <li>
                        <strong>Md Raihan Goni</strong>, Y. Zheng, R. Fuentes-Dom√≠nguez, F. P√©rez-Cota, G. S. D. Gordon,
                        <span>‚ÄúSpatiotemporal Feature Extraction in Phonon Microscopy Using Dual Attention for Cancer
                            Cell Classification‚Äù</span>,
                        <em>European Conference on Biomedical Optics (ECBO)</em>, 2025.
                        <details>
                            <summary class="paper-summary">Show Summary</summary>
                            <div class="summary-content">
                                Introduces a dual attention mechanism to extract spatiotemporal features from phonon
                                microscopy data for enhanced cancer cell classification.
                            </div>
                        </details>
                    </li>
                    <li>
                        <strong>Md Raihan Goni</strong>,
                        <span>‚ÄúTL-AttSharpNet: Automated lung image segmentation using transfer learning with depthwise
                            convolution and attention‚Äù</span>,
                        <em>IEEE 2nd National Biomedical Engineering Conference (NBEC)</em>, 2023.
                        <details>
                            <summary class="paper-summary">Show Summary</summary>
                            <div class="summary-content">
                                Presents a transfer learning-based architecture with depthwise separable
                                convolutions and attention for accurate lung image segmentation.
                            </div>
                        </details>
                    </li>
                    <li>
                        <strong>Md Raihan Goni</strong>, N. I. R. Ruhaiyem,
                        <a href="https://doi.org/10.1109/ICOCO56118.2022.10031677" target="_blank">‚ÄúSalient
                            feature
                            extraction using Attention for Brain Tumor segmentation,‚Äù</a>
                        <em>IEEE International Conference on Computing (ICOCO)</em>, 2022.
                        <details>
                            <summary class="paper-summary">Show Summary</summary>
                            <div class="summary-content">
                                Proposes an attention-based U-Net variant (Att-Sharp-U-net) to extract salient
                                features for improved brain tumor segmentation.
                            </div>
                        </details>
                    </li>
                    <li>
                        <strong>Md Raihan Goni</strong>, T. Rahman,
                        <a href="https://doi.org/10.1109/TENSYMP50017.2020.9230860" target="_blank">‚ÄúPredictive
                            Modeling on MEG Signal to Classify Hand and Wrist Movement using UNEQ and KNN,‚Äù</a>
                        <em>IEEE Region 10 Symposium (TENSYMP)</em>, 2020.
                        <details>
                            <summary class="paper-summary">Show Summary</summary>
                            <div class="summary-content">
                                Develops a statistical approach using UNEQ and KNN classifiers to predict hand
                                and
                                wrist movements from MEG signals.
                            </div>
                        </details>
                    </li>
                    <li>
                        S. S. A. Sumon, T. S., <strong>Md Raihan Goni</strong>, N. Hashem, A. Almarufuzzaman, R.
                        Rahman,
                        <a href="https://doi.org/10.1007/978-3-030-14799-0_53" target="_blank">‚ÄúViolent Crowd
                            Flow
                            Detection Using Deep Learning,‚Äù</a>
                        <em>Asian Conference on Intelligent Information and Database Systems (ACIIDS)</em>,
                        Springer, Cham, 2019.
                        <details>
                            <summary class="paper-summary">Show Summary</summary>
                            <div class="summary-content">
                                Utilizes deep learning and a novel MoBSIFT descriptor to detect violent crowd
                                flows,
                                achieving high accuracy in complex scenes.
                            </div>
                        </details>
                    </li>
                </ol>
            </div>
        </section>
        <section id="experience" class="section section-alt">
            <div class="container">
                <h2 class="section-title">Professional Experience</h2>

                <div class="experience-layout">
                    <!-- LEFT: clickable timeline -->
                    <div class="timeline experience-timeline">
                        <div class="timeline-item active" data-target="exp-phd">
                            <div class="timeline-date">2024 ‚Äì present</div>
                            <div class="timeline-content">
                                <h3>PhD Researcher (AI in Optics)</h3>
                                <p class="muted">University of Nottingham, UK</p>
                                <p>
                                    Working on AI methods for optical imaging and biomedical signal
                                    analysis,
                                    with a
                                    focus
                                    on interpretable and physics-informed deep learning models.
                                </p>
                            </div>
                        </div>

                        <div class="timeline-item" data-target="exp-lecturer">
                            <div class="timeline-date">2019 ‚Äì 2024</div>
                            <div class="timeline-content">
                                <h3>Lecturer, Computer Science & Engineering</h3>
                                <p class="muted">Southeast University, Dhaka, Bangladesh</p>
                                <p>
                                    Delivered undergraduate courses, developed course materials,
                                    assessed
                                    student
                                    performance,
                                    and supervised final-year projects.
                                </p>
                            </div>
                        </div>

                        <div class="timeline-item" data-target="exp-gra">
                            <div class="timeline-date">2021 ‚Äì 2023</div>
                            <div class="timeline-content">
                                <h3>Graduate Research Assistant</h3>
                                <p class="muted">Universiti Sains Malaysia, Penang, Malaysia</p>
                                <p>
                                    Contributed to funded research projects under the Fundamental
                                    Research Grant
                                    Scheme
                                    (FRGS),
                                    focusing on deep learning for cerebrovascular segmentation.
                                </p>
                            </div>
                        </div>
                    </div>

                    <!-- RIGHT: details card that updates -->
                    <aside class="experience-details">
                        <div class="experience-card">
                            <!-- Panel: PhD (default visible) -->
                            <div class="experience-detail-panel active" id="exp-phd">
                                <h3>Key responsibilities</h3>
                                <p class="muted">PhD Researcher ¬∑ University of Nottingham</p>
                                <ul class="bullet-list">
                                    <li>Design and evaluate deep learning models for optical imaging
                                        and
                                        biomedical
                                        signals.</li>
                                    <li>Integrate physics-informed constraints to improve robustness
                                        and
                                        interpretability.</li>
                                    <li>Collaborate with engineering and clinical teams on
                                        experimental design
                                        and
                                        analysis.</li>
                                    <li>Prepare manuscripts, conference papers, and presentations.
                                    </li>
                                </ul>
                            </div>

                            <!-- Panel: Lecturer -->
                            <div class="experience-detail-panel" id="exp-lecturer">
                                <h3>Key responsibilities</h3>
                                <p class="muted">Lecturer ¬∑ Southeast University</p>
                                <ul class="bullet-list">
                                    <li>Developed and delivered undergraduate courses in computer
                                        science and
                                        AI.</li>
                                    <li>Supervised final-year projects and guided students on
                                        research and
                                        implementation.</li>
                                    <li>Designed assessments, evaluated performance, and provided
                                        academic
                                        mentoring.
                                    </li>
                                    <li>Contributed to curriculum discussions and departmental
                                        activities.</li>
                                </ul>
                            </div>

                            <!-- Panel: GRA -->
                            <div class="experience-detail-panel" id="exp-gra">
                                <h3>Key responsibilities</h3>
                                <p class="muted">Graduate Research Assistant ¬∑ Universiti Sains
                                    Malaysia</p>
                                <ul class="bullet-list">
                                    <li>Worked on an FRGS-funded project on cerebrovascular
                                        segmentation.</li>
                                    <li>Preprocessed medical imaging datasets and implemented deep
                                        learning
                                        pipelines.
                                    </li>
                                    <li>Ran experiments, analysed results, and contributed to
                                        publications.</li>
                                    <li>Supported collaborative work with supervisors and research
                                        partners.
                                    </li>
                                </ul>
                            </div>
                        </div>
                    </aside>
                </div>
            </div>
        </section>

        <!-- Education -->
        <section id="education" class="section section-alt">
            <div class="container">
                <h2 class="section-title">Education</h2>

                <div class="card-grid">
                    <article class="card">
                        <h3>PhD in Electronics & Electrical Engineering</h3>
                        <p class="muted">University of Nottingham, Nottingham, UK ¬∑ 2024 ‚Äì present
                        </p>
                        <p><strong>Specialisation:</strong> AI in Optics / Biomedical Optics</p>
                        <p><strong>Topic:</strong> Physics-Based AI for optical properties
                            estimation for hair
                            thin
                            endoscopy device.</p>
                    </article>

                    <article class="card">
                        <h3>MSc (by Research) in Computer Science</h3>
                        <p class="muted">Universiti Sains Malaysia, Penang, Malaysia ¬∑ 2021 ‚Äì 2023
                        </p>
                        <p><strong>Specialisation:</strong> Medical Imaging, Segmentation</p>
                        <p><strong>Thesis:</strong> ECA-SKFNet: Automatic cerebrovascular
                            segmentation
                            architecture for
                            TOF-MRA images utilizing channel attention with spatial kernel
                            filtering.</p>
                    </article>

                    <article class="card">
                        <h3>BSc in Computer Science & Engineering</h3>
                        <p class="muted">North South University, Dhaka, Bangladesh ¬∑ 2015 ‚Äì 2019</p>
                        <!-- <p><strong>CGPA:</strong> 3.80 / 4.00 (Above 93%)</p> -->
                        <p><strong>Final year project:</strong> Violent crowd flow detection using
                            deep
                            learning.</p>
                    </article>
                </div>
            </div>
        </section>

        <!-- Awards & Grants -->
        <section id="awards" class="section">
            <div class="container">
                <h2 class="section-title">Awards & Grants</h2>
                <ul class="bullet-list">
                    <li>
                        <strong>Faculty of Engineering International Scholarship</strong>,
                        University of
                        Nottingham,
                        2024 ‚Äì 2027.
                    </li>
                    <li>
                        <strong>Best Paper Award</strong>, 2nd IEEE National Biomedical Engineering
                        Conference,
                        Malaysia, 2023.
                    </li>
                    <li>
                        <strong>Malaysian International Scholarship</strong>, Ministry of Education
                        Malaysia, 2022 ‚Äì
                        2024.
                    </li>
                    <li>
                        <strong>Graduate Fellowship</strong>, Universiti Sains Malaysia, 2022 ‚Äì
                        2023.
                    </li>
                    <li>
                        <strong>FRGS-Funded Project</strong> supporting MSc thesis research on
                        cerebrovascular
                        segmentation.
                    </li>
                </ul>

                <h3 class="subheading">Technical Skills</h3>
                <ul class="tag-list">
                    <li>Python</li>
                    <li>PyTorch</li>
                    <li>Keras / TensorFlow</li>
                    <li>NumPy</li>
                    <li>Pandas</li>
                    <li>Scikit-learn</li>
                    <li>OpenCV</li>
                    <li>ITK</li>
                    <li>Nibabel</li>
                    <li>Matplotlib</li>
                    <li>Seaborn</li>
                    <li>Medical image analysis</li>
                    <li>Deep learning</li>
                </ul>
            </div>
        </section>

        <!-- Meetings -->
        <section id="meeting" class="section section-alt">
            <div class="container">
                <h2 class="section-title">Meetings</h2>
                <p>
                    I am happy to speak with students, collaborators, and colleagues about research
                    ideas,
                    ongoing projects, or potential supervision. If you would like to arrange a short
                    call
                    or meeting, you are very welcome to use one of the options below.
                </p>

                <div class="meeting-grid">
                    <article class="meeting-card">
                        <h3>Check my available times</h3>
                        <p class="muted">
                            Use the link below to choose from available time slots for a short
                            online
                            meeting.
                        </p>
                        <div class="meeting-actions">
                            <a href="https://calendly.com" target="_blank" class="btn primary">
                                Schedule meeting
                            </a>
                        </div>
                    </article>

                    <article class="meeting-card">
                        <h3>Request a meeting by email</h3>
                        <p class="muted">
                            If you prefer, you can send me an email with a short note about your
                            topic
                            and a few times that work for you.
                        </p>
                        <div class="meeting-actions">
                            <a class="btn primary"
                                href="mailto:raihan.goni.1994@gmail.com">
                                Email a meeting request
                            </a>
                        </div>
                    </article>
                </div>
            </div>
        </section>

        <!-- Beyond Research / Personal -->
        <section id="beyond-research" class="section section-alt">
            <div class="container">
                <h2 class="section-title">Beyond research</h2>
                <p>
                    Outside of formal research, I enjoy activities that help me recharge, stay
                    curious,
                    and connect
                    with people from different backgrounds.
                </p>

                <div class="two-column">
                    <div>
                        <h3>Hobbies & interests</h3>
                        <ul class="bullet-list">
                            <li>
                                <strong>Games & storytelling:</strong> I enjoy story-driven and
                                strategy
                                games, and I am
                                often curious about the systems and design behind them.
                            </li>
                            <li>
                                <strong>Travel & photography:</strong> I like exploring new places,
                                noticing small
                                details in everyday life, and occasionally capturing them with a
                                camera.
                            </li>
                            <li>
                                <strong>Sports & outdoor time:</strong> I enjoy casual games like
                                badminton and taking
                                time to walk, reflect, and reset.
                            </li>
                            <li>
                                <strong>Learning about education & AI:</strong> I am interested in
                                how
                                people learn,
                                how AI changes that process, and how we can use technology
                                responsibly.
                            </li>
                        </ul>
                    </div>

                    <div>
                        <h3>Co-curricular activities</h3>
                        <ul class="bullet-list">
                            <li>
                                Participating in programming and AI-related competitions, workshops,
                                and
                                student-led
                                events.
                            </li>
                            <li>
                                Supporting students and peers through mentoring, informal advising,
                                and
                                collaborative
                                project work.
                            </li>
                            <li>
                                Engaging in discussions on AI, ethics, and higher education, and
                                sharing
                                experiences
                                across different academic systems.
                            </li>
                            <li>
                                Taking part in community or university activities that connect
                                technology with
                                real-world
                                impact.
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>

        <!-- Contact -->
        <section id="contact" class="section section-alt">
            <div class="container">
                <h2 class="section-title">Contact</h2>
                <p>
                    I am open to research collaborations in AI for biomedical optics, medical
                    imaging,
                    biomedical signal processing or any related fields.
                </p>

                <div style="margin-top: 2rem;">
                    <p><strong>Email:</strong> <a
                            href="mailto:raihan.goni.1994@gmail.com">raihan.goni.1994@gmail.com</a>
                    </p>
                    <p><strong>Location:</strong> Nottingham, United Kingdom</p>
                </div>

                <div class="social-links">
                    <!-- ORCID -->
                    <a href="https://orcid.org/0000-0002-2482-419X" target="_blank" class="social-icon"
                        aria-label="ORCID">
                        <svg viewBox="0 0 24 24">
                            <path
                                d="M12 0C5.372 0 0 5.372 0 12s5.372 12 12 12 12-5.372 12-12S18.628 0 12 0zM7.369 4.378c.525 0 .947.431.947.947s-.422.947-.947.947a.95.95 0 0 1-.947-.947c0-.525.422-.947.947-.947zm-.722 3.038h1.444v10.041H6.647V7.416zm3.562 0h3.9c3.712 0 5.344 2.653 5.344 5.025 0 2.578-2.016 5.016-5.325 5.016h-3.919V7.416zm1.444 1.303v7.444h2.297c2.359 0 4.053-1.666 4.053-3.722 0-2.056-1.694-3.722-4.053-3.722h-2.297z" />
                        </svg>
                    </a>

                    <!-- Google Scholar -->
                    <a href="https://scholar.google.com/citations?user=3hI2wOgAAAAJ&hl=en" target="_blank"
                        class="social-icon" aria-label="Google Scholar">
                        <svg viewBox="0 0 24 24">
                            <path d="M12 3L1 9l11 6 9-4.91V17h2V9L12 3zM5 13.18v4L12 21l7-3.82v-4L12 17l-7-3.82z" />
                        </svg>
                    </a>

                    <!-- LinkedIn -->
                    <a href="https://www.linkedin.com/in/raihan-goni/" target="_blank" class="social-icon"
                        aria-label="LinkedIn">
                        <svg viewBox="0 0 24 24">
                            <path
                                d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z" />
                        </svg>
                    </a>

                    <!-- GitHub -->
                    <a href="https://github.com/RaihanG" target="_blank" class="social-icon" aria-label="GitHub">
                        <svg viewBox="0 0 24 24">
                            <path
                                d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z" />
                        </svg>
                    </a>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 Md Raihan Goni. All rights reserved.</p>
        </div>
    </footer>

    <script>
        // Experience section: switch detail panel when clicking timeline items
        const expItems = document.querySelectorAll('.experience-timeline .timeline-item[data-target]');
        const expPanels = document.querySelectorAll('.experience-detail-panel');

        expItems.forEach(item => {
            item.addEventListener('click', () => {
                const targetId = item.getAttribute('data-target');

                // update active state on timeline
                expItems.forEach(i => i.classList.remove('active'));
                item.classList.add('active');

                // show matching panel on the right
                expPanels.forEach(panel => {
                    panel.classList.toggle('active', panel.id === targetId);
                });
            });
        });


        // Scroll reveal animation
        const revealElements = document.querySelectorAll(
            '.section, .card, .timeline-item, .hero-profile, .hero-text'
        );
        revealElements.forEach(el => el.classList.add('reveal'));

        const observer = new IntersectionObserver(
            (entries, obs) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('visible');
                        obs.unobserve(entry.target);
                    }
                });
            },
            { threshold: 0.15 }
        );
        revealElements.forEach(el => observer.observe(el));

        // Theme toggle
        const themeToggleBtn = document.getElementById('theme-toggle');
        const themeIcon = document.getElementById('theme-toggle-icon');

        function updateThemeIcon() {
            if (!themeIcon || !themeToggleBtn) return;
            const isDark = document.body.classList.contains('dark-theme');
            themeIcon.textContent = isDark ? '‚òÄÔ∏è' : 'üåô';
            themeToggleBtn.setAttribute(
                'aria-label',
                isDark ? 'Switch to light mode' : 'Switch to dark mode'
            );
        }

        function applyTheme(theme) {
            if (theme === 'dark') {
                document.body.classList.add('dark-theme');
            } else {
                document.body.classList.remove('dark-theme');
            }
            localStorage.setItem('theme', theme);
            updateThemeIcon();
        }

        const storedTheme = localStorage.getItem('theme');

        if (storedTheme === 'dark' || storedTheme === 'light') {
            // Respect user‚Äôs explicit choice
            applyTheme(storedTheme);
        } else {
            // Default to dark if nothing chosen yet
            applyTheme('dark');
        }


        if (themeToggleBtn) {
            themeToggleBtn.addEventListener('click', () => {
                const isDark = document.body.classList.contains('dark-theme');
                applyTheme(isDark ? 'light' : 'dark');
            });
        }
    </script>
</body>

</html>